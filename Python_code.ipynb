{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "\n",
    "# Load the Excel file\n",
    "SN_df = pd.read_excel('SN_enhancementlist_v2.xlsx')\n",
    "ADO_df = pd.read_excel('ADO_FeatureUserStorylist_V2.xlsx',skiprows=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling on SN table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "\n",
    "assignees_list = SN_df['Assigned to'].dropna().unique()\n",
    "\n",
    "nan_assignees = SN_df['Assigned to'].isna()\n",
    "\n",
    "# Randomly select values from the array to fill NaNs\n",
    "random_assignees = np.random.choice(assignees_list, size=nan_assignees.sum())\n",
    "\n",
    "# Replace NaN values in column 'Assigned to' with the randomly selected values\n",
    "SN_df.loc[nan_assignees, 'Assigned to'] = random_assignees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "requestor_list = SN_df['Requested For'].dropna().unique()\n",
    "\n",
    "nan_requestors = SN_df['Requested For'].isna()\n",
    "\n",
    "# Randomly select values from the array to fill NaNs\n",
    "random_requestors = np.random.choice(requestor_list, size=nan_requestors.sum())\n",
    "\n",
    "# Replace NaN values in column 'Assigned to' with the randomly selected values\n",
    "SN_df.loc[nan_requestors, 'Requested For'] = random_requestors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('-96 days +02:28:19')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check what the median completion time of a ticket looks like\n",
    "closed_SN = SN_df.query('State == \"Closed Complete\"')\n",
    "completion_times = closed_SN['Opened'] - closed_SN['Updated']\n",
    "completion_times.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dp/3qfg9zkn0274x0bm9wcgqjnw0000gq/T/ipykernel_85594/1164315892.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '<DatetimeArray>\n",
      "['2025-04-09 20:33:35.352502073', '2025-02-07 10:16:45.769697739',\n",
      " '2025-02-19 11:03:35.485337699', '2025-03-21 07:09:37.442607284',\n",
      " '2025-01-13 05:28:21.988925237', '2024-09-24 06:04:06.179022609',\n",
      " '2024-07-30 04:39:53.669415498', '2024-05-28 10:06:57.262467848',\n",
      " '2024-06-09 04:40:56.367255679', '2024-06-09 08:56:53.637761993',\n",
      " ...\n",
      " '2023-10-28 00:18:03.412526254', '2024-06-03 02:15:26.730302012',\n",
      " '2024-08-13 16:53:46.552376654', '2024-07-23 12:50:34.733871297',\n",
      " '2024-06-16 22:31:26.625042379', '2024-07-07 12:28:29.899520367',\n",
      " '2024-08-07 05:57:27.219696556', '2024-07-04 14:03:51.785581851',\n",
      " '2024-02-21 23:04:09.092698960', '2024-07-18 05:39:17.990839643']\n",
      "Length: 122, dtype: datetime64[ns]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  SN_df.loc[:,'Due date'] = SN_df.loc[:,'Opened'] + pd.to_timedelta(random_days, unit='D');\n"
     ]
    }
   ],
   "source": [
    "# Impute 'Due date' with a normal distribution with mean = 90 days from opened date\n",
    "\n",
    "random_days = np.random.normal(loc=90, scale=50, size=len(SN_df))\n",
    "SN_df['days_delta'] = random_days\n",
    "SN_df.loc[:,'Due date'] = SN_df.loc[:,'Opened'] + pd.to_timedelta(random_days, unit='D');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sameer.chowdary.gaddam/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download the stopwords dataset\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Get the list of English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to remove stopwords from a text string\n",
    "def remove_stopwords(text):\n",
    "    if isinstance(text, str):  # Only process strings\n",
    "        # Split the text into words, remove stopwords, and join the words back\n",
    "        return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
    "    return text  # Return the value unchanged if it's not a string\n",
    "\n",
    "# Apply the function to the 'text' column\n",
    "SN_df['Cleaned description'] = SN_df['Short description'].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling on ADO table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Replace missing values in column 'Story Points (0 - 99)' with the randomly selected values\n",
    "ADO_df['Story Points (0 - 99)'] = ADO_df['Story Points (0 - 99)'].apply(lambda x: int(np.random.uniform(1, 99)) if pd.isna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to categorize level of effort based on story points\n",
    "def categorize_effort(points):\n",
    "    if points <= 33:\n",
    "        return 'low'\n",
    "    elif points <= 66:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'high'\n",
    "\n",
    "# Apply the function to the 'points' column to create 'effort' column\n",
    "ADO_df['Level of Effort'] = ADO_df['Story Points (0 - 99)'].apply(categorize_effort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values in column 'Priority (0 - 4)' with randomly selected values\n",
    "ADO_df['Priority (0 - 4)'] = ADO_df['Priority (0 - 4)'].apply(lambda x: int(np.random.uniform(0, 5)) if pd.isna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the 'Feature Title' column\n",
    "ADO_df['Cleaned Feature Title'] = ADO_df['Feature Title'].apply(remove_stopwords)\n",
    "\n",
    "# Apply the function to the 'text' column\n",
    "ADO_df['Cleaned User Story Title'] = ADO_df['User Story Title'].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated closed cases with assigned Target Dates:\n",
      "    Iteration Path Target Date\n",
      "4        Hydrangea  2024-03-23\n",
      "7        Hydrangea  2024-03-23\n",
      "10          Dahlia  2024-04-13\n",
      "24       Sunflower  2024-05-04\n",
      "26       Hydrangea  2024-03-23\n",
      "33       Hydrangea  2024-03-23\n",
      "35       Hydrangea  2024-03-23\n",
      "43       Sunflower  2024-05-04\n",
      "44         Jasmine  2024-05-25\n",
      "45         Jasmine  2024-05-25\n",
      "47          Zinnia  2024-06-15\n",
      "48          Zinnia  2024-06-15\n",
      "54        Lavender  2024-07-27\n",
      "57        Daffodil  2024-07-06\n",
      "61        Lavender  2024-07-27\n",
      "72          Zinnia  2024-06-15\n",
      "74       Hydrangea  2024-03-23\n",
      "75        Lavender  2024-07-27\n",
      "102  Chrysanthemum  2024-08-17\n",
      "104       Hibiscus  2024-09-07\n",
      "105       Hibiscus  2024-09-07\n",
      "106       Gardenia  2024-09-28\n",
      "107       Gardenia  2024-09-28\n",
      "108         Orchid  2024-10-19\n",
      "109       Gardenia  2024-09-28\n",
      "110         Orchid  2024-10-19\n",
      "111        Jasmine  2024-05-25\n",
      "112        Jasmine  2024-05-25\n",
      "114       Hibiscus  2024-09-07\n",
      "115         Dahlia  2024-04-13\n",
      "118       Lavender  2024-07-27\n",
      "120       Lavender  2024-07-27\n",
      "121         Zinnia  2024-06-15\n",
      "122         Zinnia  2024-06-15\n",
      "123         Zinnia  2024-06-15\n",
      "124         Zinnia  2024-06-15\n",
      "125          Tulip  2024-11-09\n",
      "126          Tulip  2024-11-09\n",
      "127         Dahlia  2024-04-13\n",
      "128       Daffodil  2024-07-06\n",
      "129       Daffodil  2024-07-06\n",
      "131          Tulip  2024-11-09\n",
      "133         Dahlia  2024-04-13\n",
      "138      Hydrangea  2024-03-23\n",
      "139      Hydrangea  2024-03-23\n",
      "140      Hydrangea  2024-03-23\n",
      "141      Hydrangea  2024-03-23\n",
      "142       Lavender  2024-07-27\n",
      "143       Lavender  2024-07-27\n",
      "145      Hydrangea  2024-03-23\n",
      "147        Jasmine  2024-05-25\n",
      "149      Hydrangea  2024-03-23\n"
     ]
    }
   ],
   "source": [
    "# Remove leading backslash from 'Iteration Path' values\n",
    "ADO_df['Iteration Path'] = ADO_df['Iteration Path'].str.lstrip('\\\\')\n",
    "\n",
    "# Set 'Target Date' to November 30th for rows where 'Iteration Path' is 'Poppy'\n",
    "ADO_df.loc[ADO_df['Iteration Path'] == 'Poppy', 'Target Date'] = pd.to_datetime('2024-11-30')\n",
    "\n",
    "# Set 'Target Date' to December 15, 2024, for rows where 'Iteration Path' is 'Carnation'\n",
    "ADO_df.loc[ADO_df['Iteration Path'] == 'Carnation', 'Target Date'] = pd.to_datetime('2024-12-15')\n",
    "\n",
    "# Filter for active cases where 'Iteration Path' is empty or null\n",
    "active_no_iteration_path = ADO_df[(ADO_df['State'] == 'Active') & (ADO_df['Iteration Path'].isnull() | (ADO_df['Iteration Path'] == ''))]\n",
    "\n",
    "# Define the Iteration Paths and their corresponding Target Dates\n",
    "iteration_paths = {\n",
    "    'Rose': '2025-01-04',\n",
    "    'Lily': '2025-01-25',\n",
    "    'Marigold': '2025-02-15',\n",
    "    'Snapdragon': '2025-03-08',\n",
    "    'Bluebell': '2025-03-29',\n",
    "    'Anemone': '2025-04-30'  # Assume end of April for ongoing cases\n",
    "}\n",
    "\n",
    "# Convert Target Dates to datetime format\n",
    "iteration_paths = {key: pd.to_datetime(value) for key, value in iteration_paths.items()}\n",
    "\n",
    "# Repeat Iteration Paths to match the number of active cases needing assignment\n",
    "assignable_paths = list(iteration_paths.items()) * (len(active_no_iteration_path) // len(iteration_paths)) + random.sample(list(iteration_paths.items()), len(active_no_iteration_path) % len(iteration_paths))\n",
    "\n",
    "# Randomly shuffle and assign each Iteration Path and Target Date to the active cases without an Iteration Path\n",
    "random.shuffle(assignable_paths)\n",
    "ADO_df.loc[active_no_iteration_path.index, ['Iteration Path', 'Target Date']] = assignable_paths[:len(active_no_iteration_path)]\n",
    "\n",
    "# Define the Iteration Paths and their corresponding Target Dates for closed cases\n",
    "closed_iteration_paths = {\n",
    "    'Hydrangea': '2024-03-23',\n",
    "    'Dahlia': '2024-04-13',\n",
    "    'Sunflower': '2024-05-04',\n",
    "    'Jasmine': '2024-05-25',\n",
    "    'Zinnia': '2024-06-15',\n",
    "    'Daffodil': '2024-07-06',\n",
    "    'Lavender': '2024-07-27',\n",
    "    'Chrysanthemum': '2024-08-17',\n",
    "    'Hibiscus': '2024-09-07',\n",
    "    'Gardenia': '2024-09-28',\n",
    "    'Orchid': '2024-10-19',\n",
    "    'Tulip': '2024-11-09'\n",
    "}\n",
    "\n",
    "# Convert Target Dates to datetime format\n",
    "closed_iteration_paths = {key: pd.to_datetime(value) for key, value in closed_iteration_paths.items()}\n",
    "\n",
    "# Assign 'Target Date' for closed cases based on 'Iteration Path'\n",
    "for path, target_date in closed_iteration_paths.items():\n",
    "    ADO_df.loc[(ADO_df['State'] == 'Closed') & (ADO_df['Iteration Path'] == path), 'Target Date'] = target_date\n",
    "\n",
    "# Display the updated rows to confirm changes\n",
    "print(\"Updated closed cases with assigned Target Dates:\")\n",
    "print(ADO_df[(ADO_df['State'] == 'Closed') & (ADO_df['Iteration Path'].isin(closed_iteration_paths.keys()))][['Iteration Path', 'Target Date']])\n",
    "\n",
    "# Define the Iteration Paths and their corresponding Target Dates for closed cases, including Poppy\n",
    "closed_iteration_paths = {\n",
    "    'Hydrangea': '2024-03-23',\n",
    "    'Dahlia': '2024-04-13',\n",
    "    'Sunflower': '2024-05-04',\n",
    "    'Jasmine': '2024-05-25',\n",
    "    'Zinnia': '2024-06-15',\n",
    "    'Daffodil': '2024-07-06',\n",
    "    'Lavender': '2024-07-27',\n",
    "    'Chrysanthemum': '2024-08-17',\n",
    "    'Hibiscus': '2024-09-07',\n",
    "    'Gardenia': '2024-09-28',\n",
    "    'Orchid': '2024-10-19',\n",
    "    'Tulip': '2024-11-09',\n",
    "    'Poppy': '2024-11-30'  # Adding Poppy with its assigned end date\n",
    "}\n",
    "\n",
    "# Convert Target Dates to datetime format\n",
    "closed_iteration_paths = {key: pd.to_datetime(value) for key, value in closed_iteration_paths.items()}\n",
    "\n",
    "# List of paths and dates for random assignment\n",
    "iteration_path_dates = list(closed_iteration_paths.items())\n",
    "\n",
    "# Filter for closed cases without a Target Date assigned\n",
    "closed_no_target_date = ADO_df[(ADO_df['State'] == 'Closed') & (ADO_df['Target Date'].isnull())]\n",
    "\n",
    "# Randomly assign each row an Iteration Path and Target Date from the list\n",
    "assigned_paths = random.choices(iteration_path_dates, k=len(closed_no_target_date))\n",
    "ADO_df.loc[closed_no_target_date.index, ['Iteration Path', 'Target Date']] = assigned_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SN_df.to_excel('SN_output.xlsx', index=False)\n",
    "ADO_df.to_excel('ADO_output.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
